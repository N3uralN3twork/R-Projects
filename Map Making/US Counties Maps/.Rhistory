testing <- df[-indices, ]
table(training$class)
dim(training)
dim(testing)
table(testing$class)
n = 5000
df$Class <- df$Cover_Type
class1_ind = which(df$Class == 1)
class2_ind = which(df$Class == 2)
class3_ind = which(df$Class == 3)
class4_ind = which(df$Class == 4)
class5_ind = which(df$Class == 5)
class6_ind = which(df$Class == 6)
class7_ind = which(df$Class == 7)
class1_samp = sample(class1_ind, min(n, length(class1_ind)), replace = F)
class2_samp = sample(class2_ind, min(n, length(class2_ind)), replace = F)
class3_samp = sample(class3_ind, min(n, length(class3_ind)), replace = F)
class4_samp = sample(class4_ind, min(n, length(class4_ind)), replace = F)
class5_samp = sample(class5_ind, min(n, length(class5_ind)), replace = F)
class6_samp = sample(class6_ind, min(n, length(class6_ind)), replace = F)
class7_samp = sample(class7_ind, min(n, length(class7_ind)), replace = F)
indices = c(class1_samp, class2_samp, class3_samp, class4_samp, class5_samp,             class6_samp, class7_samp)
training <- df[indices, ]
testing <- df[-indices, ]
# Subtract by 1, since multi-class starts at 0 rn.
training$Cover_Type <- as.integer(training$Class) - 1
testing$Cover_Type <- as.integer(testing$Class) - 1
xTrain <- training %>%
select(-Cover_Type, -CoverName, -class) %>%
as.matrix()
yTrain <- training %>%
select(Cover_Type) %>%
as.matrix()
xTest <- testing %>%
select(-Cover_Type, -CoverName, -class) %>%
as.matrix()
yTest <- testing %>%
select(Cover_Type) %>%
as.matrix()
xgbTrain <- xgb.DMatrix(data=xTrain, label=yTrain)
xgbTest <- xgb.DMatrix(data=xTest, label=yTest)
# Define the parameters for multinomial classification
numClasses = length(levels(as.factor(df$Cover_Type)))
params = list(
booster="gbtree",
eta=0.001,
max_depth=5,
gamma=3,
subsample=0.75,
colsample_bytree=1,
objective="multi:softprob",
eval_metric="auc",
num_class=numClasses
)
# Define the parameters for multinomial classification
numClasses = length(levels(as.factor(df$Class)))
params = list(
booster="gbtree",
eta=0.001,
max_depth=5,
gamma=3,
subsample=0.75,
colsample_bytree=1,
objective="multi:softprob",
eval_metric="auc",
num_class=numClasses
)
set.seed(1234)
xgbMod2 <- xgb.train(
params = params,
data = xgbTrain,
nrounds = 10,
early_stopping_rounds = 2,
watchlist = list(val1 = xgb.train, val2 = xgb.test),
verbose = 0
)
set.seed(1234)
xgbMod2 <- xgb.train(
params = params,
data = xgbTrain,
nrounds = 10,
early_stopping_rounds = 2,
watchlist = list(val1 = xgbTrain, val2 = xgbTest),
verbose = 0
)
rm(df)
rm(list = ls())
knitr::opts_chunk$set(echo = TRUE)
df <- read_csv("df.csv", col_names = TRUE, progress = TRUE)
set.seed(1234)
inTrain <- createDataPartition(df$Cover_Type,
p = .75,
list = FALSE,
times = 1)
training <- df[inTrain, ]
testing <- df[-inTrain, ]
n = 5000
df$Class <- df$Cover_Type
class1_ind = which(df$Class == 1)
class2_ind = which(df$Class == 2)
class3_ind = which(df$Class == 3)
class4_ind = which(df$Class == 4)
class5_ind = which(df$Class == 5)
class6_ind = which(df$Class == 6)
class7_ind = which(df$Class == 7)
class1_samp = sample(class1_ind, min(n, length(class1_ind)), replace = F)
class2_samp = sample(class2_ind, min(n, length(class2_ind)), replace = F)
class3_samp = sample(class3_ind, min(n, length(class3_ind)), replace = F)
class4_samp = sample(class4_ind, min(n, length(class4_ind)), replace = F)
class5_samp = sample(class5_ind, min(n, length(class5_ind)), replace = F)
class6_samp = sample(class6_ind, min(n, length(class6_ind)), replace = F)
class7_samp = sample(class7_ind, min(n, length(class7_ind)), replace = F)
indices = c(class1_samp, class2_samp, class3_samp, class4_samp, class5_samp,             class6_samp, class7_samp)
training <- df[indices, ]
testing <- df[-indices, ]
# Subtract by 1, since multi-class starts at 0 rn.
training$Cover_Type <- as.integer(training$Class) - 1
testing$Cover_Type <- as.integer(testing$Class) - 1
xTrain <- training %>%
select(-Cover_Type, -CoverName, -class) %>%
as.matrix()
# Subtract by 1, since multi-class starts at 0 rn.
training$Cover_Type <- as.integer(training$Class) - 1
testing$Cover_Type <- as.integer(testing$Class) - 1
xTrain <- training %>%
select(-Cover_Type, -CoverName, -Class) %>%
as.matrix()
yTrain <- training %>%
select(Cover_Type) %>%
as.matrix()
xTest <- testing %>%
select(-Cover_Type, -CoverName, -Class) %>%
as.matrix()
yTest <- testing %>%
select(Cover_Type) %>%
as.matrix()
xgbTrain <- xgb.DMatrix(data=xTrain, label=yTrain)
xgbTest <- xgb.DMatrix(data=xTest, label=yTest)
# Define the parameters for multinomial classification
numClasses = length(levels(as.factor(df$Class)))
params = list(
booster="gbtree",
eta=0.001,
max_depth=5,
gamma=3,
subsample=0.75,
colsample_bytree=1,
objective="multi:softprob",
eval_metric="auc",
num_class=numClasses
)
set.seed(1234)
xgbMod2 <- xgb.train(
params = params,
data = xgbTrain,
nrounds = 10,
early_stopping_rounds = 2,
watchlist = list(val1 = xgbTrain, val2 = xgbTest),
verbose = 0
)
table(yTrain)
table(yTest)
# Define the parameters for multinomial classification
numClasses = length(levels(as.factor(df$Class)))
params = list(
booster="gbtree",
eta=0.001,
max_depth=5,
gamma=3,
colsample_bytree=1,
objective="multi:softprob",
eval_metric="auc",
num_class=numClasses
)
set.seed(1234)
xgbMod2 <- xgb.train(
params = params,
data = xgbTrain,
nrounds = 10,
early_stopping_rounds = 2,
watchlist = list(val1 = xgbTrain, val2 = xgbTest),
verbose = 0
)
# Define the parameters for multinomial classification
numClasses = length(levels(as.factor(df$Class)))
params = list(
booster="gbtree",
eta=0.001,
max_depth=5,
gamma=3,
subsample=0.75,
colsample_bytree=1,
objective="multi:softprob",
eval_metric="auc",
num_class=numClasses
)
# Define the parameters for multinomial classification
numClasses = length(levels(as.factor(df$Class)))
params = list(
booster="gbtree",
eta=0.001,
max_depth=5,
gamma=3,
subsample=0.75,
colsample_bytree=1,
objective="multi:softprob",
eval_metric="acc",
num_class=numClasses
)
set.seed(1234)
xgbMod2 <- xgb.train(
params = params,
data = xgbTrain,
nrounds = 10,
early_stopping_rounds = 2,
watchlist = list(val1 = xgbTrain, val2 = xgbTest),
verbose = 0
)
# Define the parameters for multinomial classification
numClasses = length(levels(as.factor(df$Class)))
params = list(
booster="gbtree",
eta=0.001,
max_depth=5,
gamma=3,
subsample=0.75,
colsample_bytree=1,
objective="multi:softprob",
eval_metric="accuracy",
num_class=numClasses
)
set.seed(1234)
xgbMod2 <- xgb.train(
params = params,
data = xgbTrain,
nrounds = 10,
early_stopping_rounds = 2,
watchlist = list(val1 = xgbTrain, val2 = xgbTest),
verbose = 0
)
# Define the parameters for multinomial classification
numClasses = length(levels(as.factor(df$Class)))
params = list(
booster="gbtree",
eta=0.001,
max_depth=5,
gamma=3,
subsample=0.75,
colsample_bytree=1,
objective="multi:softprob",
eval_metric="merror", # Multi-class classification error rate
num_class=numClasses
)
set.seed(1234)
xgbMod2 <- xgb.train(
params = params,
data = xgbTrain,
nrounds = 10,
early_stopping_rounds = 2,
watchlist = list(val1 = xgbTrain, val2 = xgbTest),
verbose = 0
)
# Review the final model and results:
xgbMod2
xgbPreds <- predict(xgbMod2, xTest, reshape = TRUE)
xgbPreds <- as.data.frame(xgbPreds)
colnames(xgbPreds) <- levels(as.factor(df$CoverName))
xgbPreds$Prediction <- apply(xgbPreds, 1, which.max)
xgbPreds$Label <- yTest - 1
accuracy = sum(xgbPreds$Prediction == xgbPreds$Label) / nrow(xgbPreds)
print(paste("Final Accuracy =", sprintf("%1.3f%%", 100 * accuracy)))
# Review the final model and results:
xgbMod2
# Define the parameters for multinomial classification
numClasses = length(levels(as.factor(df$Class)))
params = list(
booster="gbtree",
eta=0.001,
max_depth=10,
gamma=3,
subsample=0.75,
colsample_bytree=1,
objective="multi:softprob",
eval_metric="merror", # Multi-class classification error rate
num_class=numClasses
)
set.seed(1234)
xgbMod2 <- xgb.train(
params = params,
data = xgbTrain,
nrounds = 10,
early_stopping_rounds = 2,
watchlist = list(val1 = xgbTrain, val2 = xgbTest),
verbose = 0
)
# Review the final model and results:
xgbMod2
# Define the parameters for multinomial classification
numClasses = length(levels(as.factor(df$Class)))
params = list(
booster="gbtree",
eta=0.001,
max_depth= c(5, 10),
gamma=3,
subsample=0.75,
colsample_bytree=1,
objective="multi:softprob",
eval_metric="merror", # Multi-class classification error rate
num_class=numClasses
)
set.seed(1234)
xgbMod2 <- xgb.train(
params = params,
data = xgbTrain,
nrounds = 10,
early_stopping_rounds = 2,
watchlist = list(val1 = xgbTrain, val2 = xgbTest),
verbose = 0
)
# Review the final model and results:
xgbMod2
# Review the final model and results:
xgbMod2$params
# Review the final model and results:
xgbMod2$best_score
# Define the parameters for multinomial classification
numClasses = length(levels(as.factor(df$Class)))
params = list(
booster="gbtree",
eta=0.001,
max_depth= c(10),
gamma=3,
subsample=0.75,
colsample_bytree=1,
objective="multi:softprob",
eval_metric="merror", # Multi-class classification error rate
num_class=numClasses
)
set.seed(1234)
xgbMod2 <- xgb.train(
params = params,
data = xgbTrain,
nrounds = 10,
early_stopping_rounds = 2,
watchlist = list(val1 = xgbTrain, val2 = xgbTest),
verbose = 0
)
# Review the final model and results:
xgbMod2
xgbPreds <- predict(xgbMod2, xTest, reshape = TRUE)
xgbPreds <- as.data.frame(xgbPreds)
colnames(xgbPreds) <- levels(as.factor(df$CoverName))
xgbPreds$Prediction <- apply(xgbPreds, 1, which.max)
xgbPreds$Label <- yTest - 1
confusionMatrix(data = xgbPreds$Prediction, reference = xgbPreds$Label, mode = "everything")
table(xgbPreds$Prediction)
table(xgbPreds$Label)
table(yTest)
xgbPreds <- predict(xgbMod2, xgbTest, reshape = TRUE)
xgbPreds <- as.data.frame(xgbPreds)
colnames(xgbPreds) <- levels(as.factor(df$CoverName))
View(xgbPreds)
xgbPreds <- predict(xgbMod2, xgbTest, reshape = TRUE)
xgbPreds <- as.data.frame(xgbPreds)
colnames(xgbPreds) <- levels(as.factor(df$CoverName))
xgbPreds$Prediction <- apply(xgbPreds, 1, which.max)
xgbPreds$Label <- yTest
confusionMatrix(data = xgbPreds$Prediction, reference = xgbPreds$Label)
table(xgbPreds$Prediction)
table(xgbPreds$Label)
xgbPreds <- predict(xgbMod2, xgbTest, reshape = TRUE)
xgbPreds <- as.data.frame(xgbPreds)
colnames(xgbPreds) <- levels(as.factor(df$CoverName))
xgbPreds$Prediction <- apply(xgbPreds, 1, which.max)
xgbPreds$Label <- yTest
xgbPreds$Prediction
table(xgbPreds$Prediction)
table(xgbPreds$Label)
labels <- getinfo(xgbTest, "label")
labels <- getinfo(xgbTest, "label")
preds <- predict(xgbMod2, xgbTest)
labels <- getinfo(xgbTest, "label")
preds <- predict(xgbMod2, xgbTest)
errorRate <- as.numeric(sum(as.integer(pred > (1/7) != labels)) / length(labels))
labels <- getinfo(xgbTest, "label")
preds <- predict(xgbMod2, xgbTest)
errorRate <- as.numeric(sum(as.integer(pred > (1/7)) != labels)) / length(labels))
labels <- getinfo(xgbTest, "label")
preds <- predict(xgbMod2, xgbTest)
errorRate <- as.numeric(sum(as.integer(pred > (1/7)) != labels)) / length(labels)
labels <- getinfo(xgbTest, "label")
preds <- predict(xgbMod2, xgbTest)
errorRate <- as.numeric(sum(as.integer(preds > (1/7)) != labels)) / length(labels)
print(paste("Test-error Rate=", errorRate))
labels <- getinfo(xgbTest, "label")
preds <- predict(xgbMod2, xgbTest)
errorRate <- as.numeric(sum(as.integer(preds > 0.5) != labels)) / length(labels)
print(paste("Test-error Rate=", errorRate))
View(xgbPreds)
xgbPreds <- predict(xgbMod2, xgbTest, reshape = TRUE)
xgbPreds <- as.data.frame(xgbPreds)
colnames(xgbPreds) <- levels(as.factor(df$CoverName))
xgbPreds$Prediction <- apply(xgbPreds, 1, which.max)
xgbPreds$Label <- yTest + 1
confusionMatrix(data = xgbPreds$Prediction, reference = xgbPreds$Label)
rm(list = ls())
install.packages(c("backports", "BH", "brio", "broom", "cli", "conflicted", "cpp11", "credentials", "datawizard", "DBI", "devtools", "DiagrammeR", "digest", "dtplyr", "effectsize", "Exact", "fansi", "fs", "gld", "glue", "hardhat", "httpuv", "insight", "jsonlite", "knitr", "lavaan", "memoise", "multcomp", "nlme", "openssl", "parallelly", "parameters", "pillar", "pkgbuild", "pkgload", "progressr", "questionr", "raster", "rbibutils", "rcompanion", "Rcpp", "Rdpack", "readr", "remotes", "rex", "rjson", "sessioninfo", "sf", "spdep", "stringi", "terra", "testthat", "tinytex", "usethis", "vroom", "withr", "wk", "xfun", "xml2", "yaml"))
colors <- c("red", "red", "green", "green", "green", "orange")
table(colors)
install.packages("bookdown")
install.packages(c("BBmisc", "caret", "commonmark", "datawizard", "desc", "DiagrammeR", "float", "gam", "glue", "klaR", "maptools", "mgcv", "openssl", "parameters", "parsnip", "rcompanion", "Rcpp", "rlang", "rmarkdown", "sf", "styler", "survival", "withr", "workflowsets", "xfun", "XML"))
install.packages(c("nlme", "parsnip"))
install.packages("cli")
install.packages("cli")
setwd("C:/Users/miqui/OneDrive/R Projects/Map Making/US Counties Maps")
library(tidyverse)
library(tigris)
library(sf)
library(leaflet)
library(RColorBrewer)
library(classInt)
library(readxl)
USDA <- read_excel("USDA - Median Household Income Data.xlsx"
, sheet = "Data")
USStates <- tigris::states(class = "sf", year = 2021)      # ~15 MB
USCounties <- tigris::counties(class = "sf", year = 2021)  # ~130 MB
dfMerged <- geo_join(spatial_data = USCounties
, data_frame = USDA
, by_sp = "GEOID", by_df = "FIPS_code")
"Selecting the appropriate state: Ohio"
dfOhio <- dfMerged %>%
filter(State == "OH") %>%
select(STATEFP, COUNTYFP, COUNTYNS, GEOID, NAME, NAMELSAD, LSAD, CLASSFP, MTFCC, CSAFP
, CBSAFP, METDIVFP, FUNCSTAT, ALAND, AWATER, INTPTLAT, INTPTLON, State, Area_name
, Civilian_labor_force_2020, Employed_2020, Unemployed_2020, Unemployment_rate_2020
, Civilian_labor_force_2021, Employed_2021, Unemployed_2021, Unemployment_rate_2021
, Median_Household_Income_2020, Med_HH_Income_Percent_of_State_Total_2020
, rank, geometry)
dfOhioTrans <- st_transform(dfOhio, crs = 4326)
pal_fun <- colorQuantile("YlOrRd", NULL, n = 5)
myPopup <- paste0("<strong>Median HH Income ($):</strong>", dfOhioTrans$Median_Household_Income_2020)
dfOhioTrans <- dfOhioTrans %>%
mutate(myPopup = str_c("<strong>County:", NAME, "</strong>",
"<br/>",
"State: ", State,
"<br/>",
"<strong>Median HH Income ($):</strong>", dfOhioTrans$Median_Household_Income_2020,
))
dfOhioTrans <- dfOhioTrans %>%
mutate(myPopup = str_c("<strong>County:", NAME, "</strong>",
"<br/>",
"State: ", State,
"<br/>",
"<strong>Median HH Income ($):</strong>", dfOhioTrans$Median_Household_Income_2020
))
dfOhioTrans$myPopup
# quantile breaks
quantileBreaks <- classIntervals(dfOhioTrans$Median_Household_Income_2020
, n = 7, style = "quantile")
leaflet(dfOhioTrans) %>%
addPolygons(
stroke = FALSE,
fillColor = ~pal_fun(Median_Household_Income_2020),
fillOpacity = 0.8, smoothFactor = 0.5,
popup = ~myPopup,
group = "Ohio") %>%
addTiles(group = "OSM") %>%
addProviderTiles("CartoDB.DarkMatter", group = "Carto") %>%
addLegend("bottomright",
colors = brewer.pal(7, "YlOrRd"),
labels = paste0("$", format(quantileBreaks$brks[-1], digits = 2)),
title = "Median Income ($)") %>%
addLayersControl(baseGroups = c("OSM", "Carto"),
overlayGroups = c("Ohio"))
dfOhioTrans <- dfOhioTrans %>%
mutate(myPopup = str_c("<strong>County: </strong>", NAME,
"<br/>",
"<strong>State: </strong>", State,
"<br/>",
"<strong>Median HH Income ($):</strong>", dfOhioTrans$Median_Household_Income_2020
))
leaflet(dfOhioTrans) %>%
addPolygons(
stroke = FALSE,
fillColor = ~pal_fun(Median_Household_Income_2020),
fillOpacity = 0.8, smoothFactor = 0.5,
popup = ~myPopup,
group = "Ohio") %>%
addTiles(group = "OSM") %>%
addProviderTiles("CartoDB.DarkMatter", group = "Carto") %>%
addLegend("bottomright",
colors = brewer.pal(7, "YlOrRd"),
labels = paste0("$", format(quantileBreaks$brks[-1], digits = 2)),
title = "Median Income ($)") %>%
addLayersControl(baseGroups = c("OSM", "Carto"),
overlayGroups = c("Ohio"))
leaflet(dfOhioTrans) %>%
addPolygons(
stroke = FALSE,
fillColor = ~pal_fun(Median_Household_Income_2020),
fillOpacity = 0.8, smoothFactor = 0.5,
popup = ~myPopup,
group = "Ohio",
label = ~NAME) %>%
addTiles(group = "OSM") %>%
addProviderTiles("CartoDB.DarkMatter", group = "Carto") %>%
addLegend("bottomright",
colors = brewer.pal(7, "YlOrRd"),
labels = paste0("$", format(quantileBreaks$brks[-1], digits = 2)),
title = "Median Income ($)") %>%
addLayersControl(baseGroups = c("OSM", "Carto"),
overlayGroups = c("Ohio"))
