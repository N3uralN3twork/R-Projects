test <- -train
trainingdata<- College[train, ]
testdata<- College[test, ]
head(trainingdata[,1:7])
head(testdata[,1:7])
linearModel <- lm(Apps~., data = trainingdata)
summary(linearModel) #R^2 = 93.53%, p-value = 0
prediction <- predict(linearModel, newdata = testdata)
print(prediction)
MSE <- mean((testdata$Apps-prediction)^2)
MSE
library(glmnet)
x <- model.matrix(Apps~.,College)[,-1]
y <- College$Apps
y.test <- y[test]
set.seed(0)
cv.out <- cv.glmnet(x[train,],y[train],alpha=0)
bestlam <-cv.out$lambda.min
bestlam
ridge.model <- glmnet(x[train,], y[train], alpha = 0, #0 = Ridge Regression
lambda = bestlam)
ridge.pred <- predict(ridge.model, s=bestlam, newx = x[test,])
mean((ridge.pred-y.test)^2)
coef(ridge.model)
set.seed(0)
cv.out <- cv.glmnet(x[train,],y[train],alpha=1)
bestlamlasso <-cv.out$lambda.min
bestlamlasso
lasso.mod <- glmnet(x[train,],y[train],alpha = 1, #1 = Lasso Regression
lambda=bestlamlasso)
lasso.pred <- predict(lasso.mod,s=bestlamlasso,newx=x[test,])
mean((lasso.pred-y.test)^2)
coef(lasso.mod)
#Elastic Net
fit.elnet <- cv.glmnet(x[train, ], y[train], family = "gaussian", alpha = 0.5)
coef(fit.elnet)
summary(cars)
plot(pressure)
rm BOD
rm(BOD)
rm(Titanic)
library(caret)
library(caret)
library(caret)
data("GermanCredit")
inTrain <- createDataPartition(y = GermanCredit$Class, p = 0.6)
inTrain <- createDataPartition(y = GermanCredit$Class, p = 0.6)
training <- GermanCredit[inTrain, ]
inTrain <- createDataPartition(y = GermanCredit$Class, p = 0.6)
training <- GermanCredit[inTrain, ]
inTrain <- createDataPartition(y = GermanCredit$Class, p = 0.6, list = FALSE)
training <- GermanCredit[inTrain, ]
testing  <- GermanCredit[-inTrain, ]
View(training)
lmodel <- train(Class ~ Age + ForeignWorker + Property.RealEstate + Housing.Own + CreditHistory.Critical,
data = training,
method = "glm",
family = "binomial")
summary(lmodel)
View(training)
exp(coef(lmodel$finalModel))
rm(list = ls())
library(caret)
data("GermanCredit")
set.seed
inTrain <- createDataPartition(y = GermanCredit$Class, p = 0.6, list = FALSE, )
training <- GermanCredit[inTrain, ]
testing  <- GermanCredit[-inTrain, ]
lmodel <- train(Class ~ Age + ForeignWorker + Property.RealEstate + Housing.Own + CreditHistory.Critical,
data = training,
method = "glm",
family = "binomial")
exp(coef(lmodel$finalModel))
summary(lmodel)
predict(lmodel, newdata = testing, type = "response")
predict(lmodel, newdata = testing, type = "raw")
predict(lmodel, newdata = testing, type = "prob")
predictions = predict(lmodel, newdata = testing, type = "prob")
head(predictions)
rm(list = ls())
library(caret)
data("GermanCredit")
set.seed
inTrain <- createDataPartition(y = GermanCredit$Class, p = 0.6, list = FALSE, )
training <- GermanCredit[inTrain, ]
testing  <- GermanCredit[-inTrain, ]
lmodel <- train(Class ~ Age + ForeignWorker + Property.RealEstate + Housing.Own + CreditHistory.Critical,
data = training,
method = "glm",
family = "binomial")
glm <- glm(Class ~ Age + ForeignWorker + Property.RealEstate + Housing.Own + CreditHistory.Critical,
data = training,
method = "glm",
family = "binomial")
glm <- glm(formula = Class ~ Age + ForeignWorker + Property.RealEstate + Housing.Own + CreditHistory.Critical,
data = training,
method = "glm",
family = "binomial")
glm <- glm(Class ~ Age + ForeignWorker + Property.RealEstate + Housing.Own + CreditHistory.Critical,
data = training,
family = "binomial")
exp(coef(glm$coefficients))
glm$coefficients
exp(coef(lmodel$finalModel))
exp(coef(glm$coefficients))
glm$coefficients
anova(lmodel)
mod_fit_one <- glm(Class ~ Age + ForeignWorker + Property.RealEstate + Housing.Own +
CreditHistory.Critical, data=training, family="binomial")
mod_fit_two <- glm(Class ~ Age + ForeignWorker, data=training, family="binomial")
anova(mod_fit_one, mod_fit_two, test ="Chisq")
mod_fit_one <- glm(Class ~ Age + ForeignWorker + Property.RealEstate + Housing.Own +
CreditHistory.Critical, data=training, family="binomial")
mod_fit_two <- glm(Class ~ Age + ForeignWorker, data=training, family="binomial")
anova(mod_fit_one, mod_fit_two, test ="Chisq")
install.packages("pscl")
library(psc1)
library(pscl)
pR2(mod_fit_one)
library(pscl)
pR2(mod_fit_one)
install.packages("MKmisc")
library(MKmisc)
library(MKmisc)
remove.packages("MKmisc", lib="~/R/win-library/3.5")
library(rms)
install.packages("rms")
varImp(lmodel)
preds = predict(lmodel, newdata = testing)
confusionMatrix(data = pred, reference = testing$Class)
preds = predict(lmodel, newdata = testing)
confusionMatrix(data = preds, reference = testing$Class)
library(data.table)
exp(cbind(OR = coef(mylogit), confint(mylogit)))
library(caret)
data("GermanCredit")
set.seed
inTrain <- createDataPartition(y = GermanCredit$Class, p = 0.6, list = FALSE, )
training <- GermanCredit[inTrain, ]
testing  <- GermanCredit[-inTrain, ]
lmodel <- train(Class ~ Age + ForeignWorker + Property.RealEstate + Housing.Own + CreditHistory.Critical,
data = training,
method = "glm",
family = "binomial")
exp(coef(lmodel$finalModel))
exp(cbind(OR = coef(mylogit), confint(mylogit)))
exp(cbind(OR = coef(lmodel), confint(lmodel)))
logistic = glm(Class ~ Age + ForeignWorker + Property.RealEstate + Housing.Own + CreditHistory.Critical,
data = training,
family = "binomial"))
logistic = glm(Class ~ Age + ForeignWorker + Property.RealEstate + Housing.Own + CreditHistory.Critical,
data = training,
family = "binomial")
exp(cbind(OR = coef(logistic), confint(logistic)))
summary(logistic)$coefficients[, 4]
logistic = glm(Class ~ Age + ForeignWorker + Property.RealEstate + Housing.Own + CreditHistory.Critical,
data = training,
family = "binomial")
exp(cbind(OR = coef(logistic), confint(logistic), p-Value = summary(logistic)$coefficients[, 4]
logistic = glm(Class ~ Age + ForeignWorker + Property.RealEstate + Housing.Own + CreditHistory.Critical,
data = training,
family = "binomial")
exp(cbind(OR = coef(logistic), confint(logistic), pValue = summary(logistic)$coefficients[, 4]))
logistic = glm(Class ~ Age + ForeignWorker + Property.RealEstate + Housing.Own + CreditHistory.Critical,
data = training,
family = "binomial")
exp(cbind(OR = coef(logistic), confint(logistic), pValue = summary(logistic)$coefficients[, 5]))
logistic = glm(Class ~ Age + ForeignWorker + Property.RealEstate + Housing.Own + CreditHistory.Critical,
data = training,
family = "binomial")
exp(cbind(OR = coef(logistic), confint(logistic), pValue = summary(logistic)$coefficients[, 3]))
logistic = glm(Class ~ Age + ForeignWorker + Property.RealEstate + Housing.Own + CreditHistory.Critical,
data = training,
family = "binomial")
exp(cbind(OR = coef(logistic), confint(logistic), pValue = summary(logistic)$coefficients[, 1]))
logistic = glm(Class ~ Age + ForeignWorker + Property.RealEstate + Housing.Own + CreditHistory.Critical,
data = training,
family = "binomial")
exp(cbind(OR = coef(logistic), confint(logistic), pValue = summary(logistic)$coefficients[, 4]))
logistic = glm(Class ~ Age + ForeignWorker + Property.RealEstate + Housing.Own + CreditHistory.Critical,
data = training,
family = "binomial")
exp(cbind(OR = coef(logistic), confint(logistic), pValue = (summary(logistic)$coefficients[, 4])-1))
str(summary(logistic))
str(summary(logistic$coefficients))
str(summary(logistic$coefficients[,4]))
summary(logistic)$coefficients[, 4]
summary(logistic)
logistic = glm(Class ~ Age + ForeignWorker + Property.RealEstate + Housing.Own + CreditHistory.Critical,
data = training,
family = "binomial")
cbind(OR = exp(coef(logistic)), exp(confint(logistic)), pValue = (summary(logistic)$coefficients[, 4]))
summary(logistic)
anova(logistic)
library(caret)
data("GermanCredit")
mydata <- read.csv("https://stats.idre.ucla.edu/stat/data/binary.csv")
View(mydata)
library(caret)
data("GermanCredit")
mydata <- read.csv("https://stats.idre.ucla.edu/stat/data/binary.csv")
mydata$rank <- factor(mydata$rank)
set.seed
inTrain <- createDataPartition(y = GermanCredit$Class, p = 0.6, list = FALSE, )
training <- GermanCredit[inTrain, ]
testing  <- GermanCredit[-inTrain, ]
set.seed
inTrain <- createDataPartition(y = GermanCredit$Class, p = 0.6, list = FALSE, )
training <- GermanCredit[inTrain, ]
testing  <- GermanCredit[-inTrain, ]
set.seed
inTrain <- createDataPartition(y = GermanCredit$Class, p = 0.6, list = FALSE, )
training <- GermanCredit[inTrain, ]
testing  <- GermanCredit[-inTrain, ]
myprobit <- glm(admit ~ gre + gpa + rank,
family = binomial(link = "probit"),
data = mydata)
myprobit <- glm(admit ~ gre + gpa + rank,
family = binomial(link = "probit"),
data = mydata)
summary(myprobit)
require(ISLR)
head(College)
names(College)
College = ISLR::College
library(readr)
trainingdata <- read_csv("C:/Users/MatthiasQ.MATTQ/Desktop/Python Projects/Sci-kit Learn/Datasets/TrainingData.csv")
View(trainingdata)
library(readr)
testdata <- read_csv("C:/Users/MatthiasQ.MATTQ/Desktop/Python Projects/Sci-kit Learn/Datasets/TestingData.csv")
View(testdata)
#General Linear Model
linearModel <- lm(Apps~., data = trainingdata)
summary(linearModel) #R^2 = 93.53%, p-value = 0
prediction <- predict(linearModel, newdata = testdata)
print(prediction)
MSE <- mean((testdata$Apps-prediction)^2)
MSE
x <- model.matrix(Apps~., trainingdata)[,-1]
View(College)
rm(list = ls())
install.packages(c("jpeg", "rgdal"))
library(readr)
mydata <- read.csv("https://stats.idre.ucla.edu/stat/data/binary.csv")
View(mydata)
head(mydata, 4)
mydata$rank <- factor(mydata$rank)
logit <- glm(admit ~ gre + gpa + rank,
data = mydata,
family = binomial(link = "logit"))
summary(logit)
exp(logit$coefficients)
exp(cbind(OR = coef(logit), confint(logit)))
install.packages(c("geojsonio", "hms", "prodlim", "tinytex"))
swiss <- datasets::swiss
View(swiss)
#Define x and y
x <- model.matrix(Fertility ~., data = swiss)[,-1]
y <- swiss$Fertility
View(x)
#Define lambda to use
lambda <- 10^seq(from = 10, to = -2, length = 100)
#To prove the above statements that we made about lambda:
library(glmnet)
set.seed(489)
train <- sample(1:nrow(x), nrow(x)/2)
test  <- (-train)
ytest <- y[test]
#Fit your models
#Ordinary Least Squares
SimpleLinear <- lm(Fertility ~.,
data = swiss)
summary(SimpleLinear)
#Ridge Regression
Ridge <- glmnet(x, y, alpha = 0, #0 = ridge
lambda = lambda)
predict(Ridge, s = 0, exact = True, type = "coefficents")
predict(Ridge, s = 0, exact = True, type = "coefficients")
predict(Ridge, s = 0, exact = TRUE, type = "coefficients")
predict(Ridge, s = 0, exact = T, type = "coefficients")[1:6, ]
predict(Ridge, s = 0, exact = T, type = "coefficients")[1:6, ]
predict(Ridge, s = 0, exact = T, type = 'coefficients')[1:6,]
coef(Ridge)
coef(Ridge)[1:6,]
predict(Ridge, s = 0, type = 'coefficients')[1:6,]
predict(Ridge, s = 0, type = 'coefficients', exact = TRUE)[1:6,]
predict(Ridge, s = 0, type = 'coefficients', exact = TRUE, x, y)[1:6,]
predict(Ridge, x, y, s = 0, type = 'coefficients', exact = TRUE)[1:6,]
predict(Ridge, s = 0, x = x, y = y,
type = 'coefficients', exact = TRUE)[1:6,]
#Just like you saw with Michelle's book work, we can choose the best lambda
#value instead of relying on a bunch of lambdas
cv.out <- cv.glmnet(x[train], y[train], alpha = 0)
#Just like you saw with Michelle's book work, we can choose the best lambda
#value instead of relying on a bunch of lambdas
cv.out <- cv.glmnet(x[train,], y[train,], alpha = 0)
#Just like you saw with Michelle's book work, we can choose the best lambda
#value instead of relying on a bunch of lambdas
cv.out <- cv.glmnet(x[train,], y[train], alpha = 0)
bestLambda <- cv.out$lambda.min
print(bestLambda)
RidgeModel <- glmnet(x[train, ], y[train], alpha = 0, lambda = lambda)
#Predictions
RidgePreds <- predict(RidgeModel, s = bestLambda, newx = x[test, ])
SwissLM <- lm(Fertility ~.,
data = swiss,
subset = train)
SwissPred <- predict(SwissLM, newdata = swiss[test, ])
#Checking model performance with MSE:
mean(SwissPred - ytest)^2)
#Checking model performance with MSE:
mean(SwissPred - ytest)^2
#Checking model performance with MSE:
mean((SwissPred - ytest)^2)
#106.0087
mean((RidgePreds-ytest)^2)
#Lasso Regression:
#Lasso takes the absolute value of the coefficient estimates
Lasso <- glmnet(x[train, ], y[train], alpha = 1 #Specify lasso
lambda = lambda)
#Lasso Regression:
#Lasso takes the absolute value of the coefficient estimates
Lasso <- glmnet(x[train, ], y[train], alpha = 1, #Specify lasso
lambda = lambda)
LassoPreds <- predict(Lasso, s = bestLambda, newx = x[test, ])
#MSE
mean((LassoPreds-ytest)^2)
install.packages(c("glmnet", "haven", "Hmisc", "polspline", "prodlim", "quantreg", "Rcpp", "sp", "survival", "testthat"))
install.packages(c("glmnet", "knitr", "R6", "rmarkdown", "survival", "xfun"))
install.packages(c("AlgDesign", "leaflet", "prodlim", "RcppEigen", "rms", "scales"))
install.packages(c("AlgDesign", "digest", "prodlim", "RcppEigen", "rlang", "rms", "scales"))
install.packages(c("AlgDesign", "BH", "callr", "caTools", "cli", "curl", "data.table", "DBI", "e1071", "htmlTable", "maptools", "multcomp", "odbc", "plotrix", "plyr", "quantreg", "rgdal", "RgoogleMaps", "rmarkdown", "RSQLite", "SparseM", "survival", "testthat", "tfdatasets", "tinytex", "TTR"))
install.packages(c("recipes", "reticulate", "RSQLite", "TTR", "vctrs"))
install.packages(c("BH", "mime", "pillar", "reticulate", "RSQLite", "TTR", "vctrs"))
install.packages("mime")
setwd("C:/Users/MatthiasQ.MATTQ/Desktop/R Projects")
getwd()
list.files()
#Read in the practice dataset
library(readxl)
data1 <- read_excel("Practice SF-36 data.xlsx",
sheet = "Practice SF-36 data")
data1 <- as.data.frame(data1)
View(data1)
#The goal of this project is to retrive stock quotes, like I've done before
#However, I lost the file
#Import the necessary libraries
library(quantmod) #Retrieves the data
library(xlsx)     #Write to an excel file
library(lubridate) #To split dates
#List the stock prices you would like to receive:
Symbols = c("AAPL", "AMZN", "FB", "NFLX", "GOOGL", "NVDA",
"IBM", "INTC", "MSFT", "QCOM", "TSM", "MS") #Tech stocks
Symbols = sort(Symbols) #Sort in alphabetical order
Companies = c("Apple", "Amazon", "Facebook", "Google", "IBM", "Intel", "Morgan Stanley",
"Microsoft", "Netflix", "Nvidia", "Qualcomm", "Taiwan Semiconductor")
#Retrive the information
Quotes <- getQuote(Symbols, src = "yahoo")
"Join new columns:"
Quotes = cbind(Companies, Quotes)
Quotes$Weekday = weekdays(as.Date(Quotes$`Trade Time`))
"Create an excel workbook"
#Can change in the future if needed
file = "C:/Users/MatthiasQ.MATTQ/Desktop/R Projects/Quotes.xlsx"
write.xlsx(Quotes, file = file, sheetName = "Quotes",
col.names = TRUE, row.names = TRUE, append = FALSE)
#This took like 40 minutes to build lol.
rm(list = ls())
#Import the necessary libraries
library(quantmod) #Retrieves the data
library(xlsx)     #Write to an excel file
library(lubridate) #To split dates
setwd("C:/Users/miqui/OneDrive/R Projects")
#The goal of this project is to retrive stock quotes, like I've done before
#However, I lost the file
#Import the necessary libraries
library(quantmod) #Retrieves the data
library(xlsx)     #Write to an excel file
library(lubridate) #To split dates
#List the stock prices you would like to receive:
Symbols = c("AAPL", "AMZN", "FB", "NFLX", "GOOGL", "NVDA",
"IBM", "INTC", "MSFT", "QCOM", "TSM", "MS") #Tech stocks
Symbols = sort(Symbols) #Sort in alphabetical order
Companies = c("Apple", "Amazon", "Facebook", "Google", "IBM", "Intel", "Morgan Stanley",
"Microsoft", "Netflix", "Nvidia", "Qualcomm", "Taiwan Semiconductor")
#Retrive the information
Quotes <- getQuote(Symbols, src = "yahoo")
"Join new columns:"
Quotes = cbind(Companies, Quotes)
Quotes$Weekday = weekdays(as.Date(Quotes$`Trade Time`))
"Create an excel workbook"
#Can change in the future if needed
file = "C:/Users/MatthiasQ.MATTQ/Desktop/R Projects/Quotes.xlsx"
write.xlsx(Quotes, file = file, sheetName = "Quotes",
col.names = TRUE, row.names = TRUE, append = FALSE)
#This took like 40 minutes to build lol.
#Can change in the future if needed
file = "C:\Users\miqui\OneDrive\R Projects\Quotes.xlsx"
#Can change in the future if needed
file = "C:/Users/miqui/OneDrive/R ProjectsQuotes.xlsx"
#The goal of this project is to retrive stock quotes, like I've done before
#However, I lost the file
#Import the necessary libraries
library(quantmod) #Retrieves the data
library(xlsx)     #Write to an excel file
library(lubridate) #To split dates
#List the stock prices you would like to receive:
Symbols = c("AAPL", "AMZN", "FB", "NFLX", "GOOGL", "NVDA",
"IBM", "INTC", "MSFT", "QCOM", "TSM", "MS") #Tech stocks
Symbols = sort(Symbols) #Sort in alphabetical order
Companies = c("Apple", "Amazon", "Facebook", "Google", "IBM", "Intel", "Morgan Stanley",
"Microsoft", "Netflix", "Nvidia", "Qualcomm", "Taiwan Semiconductor")
#Retrive the information
Quotes <- getQuote(Symbols, src = "yahoo")
"Join new columns:"
Quotes = cbind(Companies, Quotes)
Quotes$Weekday = weekdays(as.Date(Quotes$`Trade Time`))
"Create an excel workbook"
#Can change in the future if needed
file = "C:/Users/miqui/OneDrive/R ProjectsQuotes.xlsx"
write.xlsx(Quotes, file = file, sheetName = "Quotes",
col.names = TRUE, row.names = TRUE, append = FALSE)
#This took like 40 minutes to build lol.
rm(list = ls())
library(quantmod) #Retrieves the data
library(xlsx)     #Write to an excel file
library(lubridate) #To split dates
#List the stock prices you would like to receive:
Symbols = c("AAPL", "AMZN", "FB", "NFLX", "GOOGL", "NVDA",
"IBM", "INTC", "MSFT", "QCOM", "TSM", "MS") #Tech stocks
Symbols = sort(Symbols) #Sort in alphabetical order
Symbols
Companies = c("Apple", "Amazon", "Facebook", "Google", "IBM", "Intel", "Morgan Stanley",
"Microsoft", "Netflix", "Nvidia", "Qualcomm", "Taiwan Semiconductor")
#Retrive the information
Quotes <- getQuote(Symbols, src = "yahoo")
Quotes
Quotes = cbind(Companies, Quotes)
Quotes$Weekday = weekdays(as.Date(Quotes$`Trade Time`))
#Can change in the future if needed
file = "C:/Users/miqui/OneDrive/R ProjectsQuotes.xlsx"
write.xlsx(Quotes, file = file, sheetName = "Quotes",
col.names = TRUE, row.names = TRUE, append = FALSE)
install.packages("xlsx")
library(xlsx)     #Write to an excel file
write.xlsx(Quotes, file = file, sheetName = "Quotes",
col.names = TRUE, row.names = TRUE, append = FALSE)
Quotes
write.xlsx(Quotes, file = file, sheetName = "Quotes",
col.names = TRUE, row.names = TRUE, append = FALSE)
rm(list = ls())
#The goal of this project is to retrive stock quotes, like I've done before
#However, I lost the file
#Import the necessary libraries
library(quantmod) #Retrieves the data
library(xlsx)     #Write to an excel file
library(lubridate) #To split dates
#List the stock prices you would like to receive:
Symbols = c("AAPL", "AMZN", "FB", "NFLX", "GOOGL", "NVDA",
"IBM", "INTC", "MSFT", "QCOM", "TSM", "MS") #Tech stocks
Symbols = sort(Symbols) #Sort in alphabetical order
Companies = c("Apple", "Amazon", "Facebook", "Google", "IBM", "Intel", "Morgan Stanley",
"Microsoft", "Netflix", "Nvidia", "Qualcomm", "Taiwan Semiconductor")
#Retrive the information
Quotes <- getQuote(Symbols, src = "yahoo")
"Join new columns:"
Quotes = cbind(Companies, Quotes)
Quotes$Weekday = weekdays(as.Date(Quotes$`Trade Time`))
"Create an excel workbook"
#Can change in the future if needed
file = "C:/Users/miqui/OneDrive/R Projects/Quotes.xlsx"
write.xlsx(Quotes, file = file, sheetName = "Quotes",
col.names = TRUE, row.names = TRUE, append = FALSE)
#This took like 40 minutes to build lol.
install.packages("rsample")
setwd("C:/Users/miqui/OneDrive/R Projects")
library(rsample)
library(dplyr)
library(caret)
attrition <- attrition %>%
mutate(JobLevel = factor(JobLevel),
StockOptionLevel = factor(StockOptionLevel),
TrainingTimesLastYear = factor(TrainingTimesLastYear))
set.seed(123)
split <- initial_split(data = attrition, prop = 0.7, strata = "Attrition")
train <- training(split)
test  <- testing(split)
prop.table(table(train$Attrition))
prop.table(table(test$Attrition))
train %>%
select(Age, DailyRate, DistanceFromHome, HourlyRate, MonthlyIncome, MonthlyRate) %>%
gather(metric, value) %>%
ggplot(aes(value, fill = metric)) +
geom_density(show.legend = FALSE) +
facet_wrap(~ metric, scales = "free")
features <- setdiff(names(train), "Attrition")
x <- train[, features]
y <- train$Attrition
trControl <- trainControl(method = "cv", number = 10)
nb.fit <- train(
x = x,
y = y,
method = "nb",
trControl = trControl
)
confusionMatrix(nb.fit)
plot(nb.fit)
preds <- predict(nb.fit, newdata = test)
confusionMatrix(preds, reference = test$Attrition)
library(caret)
rm(list = ls())
library(caret)
